{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db632b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Total Dataset: 150992\n",
      "📂 Classes: ['A', 'AFIB', 'AFL', 'L', 'N', 'R', 'V']\n",
      "\n",
      "📚 Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_8791/2408246260.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "/tmp/ipykernel_8791/2408246260.py:57: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()  # AMP scaler\n",
      "Epoch 1/5:   0%|          | 0/3775 [00:00<?, ?it/s]/tmp/ipykernel_8791/2408246260.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_8791/2408246260.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "/tmp/ipykernel_8791/2408246260.py:57: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()  # AMP scaler\n",
      "Epoch 1/5:   0%|          | 0/3775 [00:00<?, ?it/s]/tmp/ipykernel_8791/2408246260.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_8791/2408246260.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "/tmp/ipykernel_8791/2408246260.py:57: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()  # AMP scaler\n",
      "Epoch 1/5:   0%|          | 0/3775 [00:00<?, ?it/s]/tmp/ipykernel_8791/2408246260.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_8791/2408246260.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "/tmp/ipykernel_8791/2408246260.py:57: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()  # AMP scaler\n",
      "Epoch 1/5:   0%|          | 0/3775 [00:00<?, ?it/s]/tmp/ipykernel_8791/2408246260.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_8791/2408246260.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "/tmp/ipykernel_8791/2408246260.py:57: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()  # AMP scaler\n",
      "Epoch 1/5:   0%|          | 0/3775 [00:00<?, ?it/s]/tmp/ipykernel_8791/2408246260.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Hasil evaluasi disimpan ke:\n",
      " - kfold_finetune_vit_evaluation.csv (per-class metrics)\n",
      " - kfold_finetune_vit_accuracy.csv (accuracy per fold)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# ====== Step 1: Dataset dan Transform ======\n",
    "train_dir = \"/workspace/dataset_vit_aug1/dataset_vit_aug/train\"\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "labels = train_dataset.targets  # Label untuk StratifiedKFold\n",
    "\n",
    "print(f\"📊 Total Dataset: {len(train_dataset)}\")\n",
    "print(f\"📂 Classes: {train_dataset.classes}\")\n",
    "\n",
    "# ====== Step 2: K-Fold Setup ======\n",
    "n_splits = 5\n",
    "batch_size = 32\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_path = \"model_vit_tuning.pth\"\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "all_reports = []\n",
    "fold_accuracies = []\n",
    "\n",
    "# ====== Step 3: Loop K-Fold ======\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(labels)), labels)):\n",
    "    print(f\"\\n📚 Fold {fold + 1}\")\n",
    "\n",
    "    train_subset = Subset(train_dataset, train_idx)\n",
    "    val_subset = Subset(train_dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # ====== Step 4: Load Model dan Fine-Tune dari .pth ======\n",
    "    model = models.vit_b_16(pretrained=True)\n",
    "    model.heads = nn.Sequential(\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(model.heads.head.in_features, len(train_dataset.classes))\n",
    "    )\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scaler = GradScaler()  # AMP scaler\n",
    "\n",
    "    # ====== Step 5: Training Loop with AMP & tqdm ======\n",
    "    for epoch in range(5):  # Ubah jumlah epoch jika perlu\n",
    "        model.train()\n",
    "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/5\", leave=False)\n",
    "        for images, labels in loop:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # ====== Step 6: Evaluasi per fold ======\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            y_pred.extend(preds)\n",
    "            y_true.extend(labels.numpy())\n",
    "\n",
    "    report = classification_report(y_true, y_pred, output_dict=True, target_names=train_dataset.classes)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    fold_accuracies.append({'Fold': f'Fold {fold+1}', 'Accuracy': accuracy})\n",
    "    all_reports.append(report)\n",
    "\n",
    "# ====== Step 7: Simpan hasil evaluasi ======\n",
    "rows = []\n",
    "for i, report in enumerate(all_reports):\n",
    "    for cls in train_dataset.classes:\n",
    "        row = {\n",
    "            'Fold': f'Fold {i+1}',\n",
    "            'Class': cls,\n",
    "            'Precision': report[cls]['precision'],\n",
    "            'Recall': report[cls]['recall'],\n",
    "            'F1-Score': report[cls]['f1-score'],\n",
    "            'Support': report[cls]['support']\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "df_summary = pd.DataFrame(rows)\n",
    "df_summary.to_csv(\"kfold_finetune_vit_evaluation.csv\", index=False)\n",
    "\n",
    "df_acc = pd.DataFrame(fold_accuracies)\n",
    "df_acc.to_csv(\"kfold_finetune_vit_accuracy.csv\", index=False)\n",
    "\n",
    "print(\"\\n✅ Hasil evaluasi disimpan ke:\")\n",
    "print(\" - kfold_finetune_vit_evaluation.csv (per-class metrics)\")\n",
    "print(\" - kfold_finetune_vit_accuracy.csv (accuracy per fold)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a70e30ae-b336-4d89-a779-c0b80f5cf11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.3)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.1 scikit-learn-1.7.0 scipy-1.15.3 threadpoolctl-3.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e65b62b3-211c-4887-bc06-cff066ef4d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.3.0 pytz-2025.2 tzdata-2025.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "939343c8-b693-4d0a-b970-ebb0c7566a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.4.1+cu124)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.19.1+cu124)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.4.1+cu124)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.2.65 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.2.65)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.0.44 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.0.44)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.119 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.119)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.0.99 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.0.99)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.0.142 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.0.142)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.99)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.99)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e55454f9-26e6-46db-b631-d92baf11293d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffad4b8c-f135-42c3-a68b-0cfaca1f6cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85cb988f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Total Dataset: 150992\n",
      "📂 Classes: ['A', 'AFIB', 'AFL', 'L', 'N', 'R', 'V']\n",
      "\n",
      "📚 Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /root/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n",
      "100.0%\n",
      "/tmp/ipykernel_390/3650007387.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "/tmp/ipykernel_390/3650007387.py:70: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "Epoch 1/10:   0%|          | 0/3775 [00:00<?, ?it/s]/tmp/ipykernel_390/3650007387.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_390/3650007387.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "/tmp/ipykernel_390/3650007387.py:70: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "Epoch 1/10:   0%|          | 0/3775 [00:00<?, ?it/s]/tmp/ipykernel_390/3650007387.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_390/3650007387.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "/tmp/ipykernel_390/3650007387.py:70: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "Epoch 1/10:   0%|          | 0/3775 [00:00<?, ?it/s]/tmp/ipykernel_390/3650007387.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_390/3650007387.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "/tmp/ipykernel_390/3650007387.py:70: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "Epoch 1/10:   0%|          | 0/3775 [00:00<?, ?it/s]/tmp/ipykernel_390/3650007387.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_390/3650007387.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "/tmp/ipykernel_390/3650007387.py:70: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "Epoch 1/10:   0%|          | 0/3775 [00:00<?, ?it/s]/tmp/ipykernel_390/3650007387.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏆 Fold terbaik: Fold 4 dengan akurasi 0.9925\n",
      "✅ Metrik per kelas dari fold terbaik disimpan ke: best_fold_class_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# ====== Step 1: Dataset dan Transform ======\n",
    "train_dir = \"/workspace/dataset_vit_aug1/dataset_vit_aug/train\"\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "labels = train_dataset.targets  # Label untuk StratifiedKFold\n",
    "\n",
    "print(f\"📊 Total Dataset: {len(train_dataset)}\")\n",
    "print(f\"📂 Classes: {train_dataset.classes}\")\n",
    "\n",
    "# ====== Step 2: Konfigurasi K-Fold dan Training ======\n",
    "n_splits = 5\n",
    "batch_size = 32\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path = \"model_vit_tuning.pth\"\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "all_reports = []\n",
    "fold_accuracies = []\n",
    "\n",
    "# ====== Step 3: Fungsi Hitung Sensitivity dan Specificity ======\n",
    "def calculate_specificity_sensitivity(y_true, y_pred, labels):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=range(len(labels)))\n",
    "    metrics = {}\n",
    "    for i, label in enumerate(labels):\n",
    "        TP = cm[i, i]\n",
    "        FN = cm[i, :].sum() - TP\n",
    "        FP = cm[:, i].sum() - TP\n",
    "        TN = cm.sum() - (TP + FP + FN)\n",
    "        sensitivity = TP / (TP + FN) if TP + FN != 0 else 0\n",
    "        specificity = TN / (TN + FP) if TN + FP != 0 else 0\n",
    "        metrics[label] = {'sensitivity': sensitivity, 'specificity': specificity}\n",
    "    return metrics\n",
    "\n",
    "# ====== Step 4: Proses K-Fold Cross Validation ======\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(labels)), labels)):\n",
    "    print(f\"\\n📚 Fold {fold + 1}\")\n",
    "\n",
    "    train_subset = Subset(train_dataset, train_idx)\n",
    "    val_subset = Subset(train_dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Load dan sesuaikan model\n",
    "    model = models.vit_b_16(pretrained=True)\n",
    "    model.heads = nn.Sequential(\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(model.heads.head.in_features, len(train_dataset.classes))\n",
    "    )\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # ====== Step 5: Proses Training per Fold ======\n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/10\", leave=False)\n",
    "        for images, labels in loop:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # ====== Step 6: Evaluasi Model ======\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            y_pred.extend(preds)\n",
    "            y_true.extend(labels.numpy())\n",
    "\n",
    "    report = classification_report(y_true, y_pred, output_dict=True, target_names=train_dataset.classes)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    sensi_speci = calculate_specificity_sensitivity(y_true, y_pred, train_dataset.classes)\n",
    "\n",
    "    fold_result = {\n",
    "        'fold': fold + 1,\n",
    "        'accuracy': accuracy,\n",
    "        'report': report,\n",
    "        'sensi_speci': sensi_speci\n",
    "    }\n",
    "    all_reports.append(fold_result)\n",
    "    fold_accuracies.append({'Fold': f'Fold {fold+1}', 'Accuracy': accuracy})\n",
    "\n",
    "# ====== Step 7: Simpan Evaluasi Detail Per Fold ======\n",
    "rows = []\n",
    "for fold_result in all_reports:\n",
    "    fold_number = fold_result['fold']\n",
    "    accuracy = fold_result['accuracy']\n",
    "    report = fold_result['report']\n",
    "    sensi_speci = fold_result['sensi_speci']\n",
    "\n",
    "    for cls in train_dataset.classes:\n",
    "        precision = report[cls]['precision']\n",
    "        recall = report[cls]['recall']\n",
    "        f1 = report[cls]['f1-score']\n",
    "        support = report[cls]['support']\n",
    "        sensitivity = sensi_speci[cls]['sensitivity']\n",
    "        specificity = sensi_speci[cls]['specificity']\n",
    "\n",
    "        row = {\n",
    "            'Fold': f\"Fold {fold_number}\",\n",
    "            'Class': cls,\n",
    "            'Accuracy': round(accuracy, 4),\n",
    "            'Precision': round(precision, 4),\n",
    "            'Recall': round(recall, 4),\n",
    "            'F1-Score': round(f1, 4),\n",
    "            'Support': support,\n",
    "            'Sensitivity': round(sensitivity, 4),\n",
    "            'Specificity': round(specificity, 4)\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "df_summary = pd.DataFrame(rows)\n",
    "df_summary.to_csv(\"kfold_finetune_vit_evaluation.csv\", index=False)\n",
    "\n",
    "# ====== Step 8: Identifikasi Fold Terbaik & Simpan Tabel Detail ======\n",
    "best_fold = max(all_reports, key=lambda x: x['accuracy'])\n",
    "print(f\"\\n🏆 Fold terbaik: Fold {best_fold['fold']} dengan akurasi {best_fold['accuracy']:.4f}\")\n",
    "\n",
    "best_rows = []\n",
    "for cls in train_dataset.classes:\n",
    "    precision = best_fold['report'][cls]['precision']\n",
    "    recall = best_fold['report'][cls]['recall']\n",
    "    f1 = best_fold['report'][cls]['f1-score']\n",
    "    sensitivity = best_fold['sensi_speci'][cls]['sensitivity']\n",
    "    specificity = best_fold['sensi_speci'][cls]['specificity']\n",
    "\n",
    "    best_rows.append({\n",
    "        'Class': cls,\n",
    "        'Precision': round(precision, 4),\n",
    "        'Sensitivity': round(sensitivity, 4),\n",
    "        'Specificity': round(specificity, 4),\n",
    "        'F1-Score': round(f1, 4)\n",
    "    })\n",
    "\n",
    "df_best = pd.DataFrame(best_rows)\n",
    "df_best.to_csv(\"best_fold_class_metrics.csv\", index=False)\n",
    "print(\"✅ Metrik per kelas dari fold terbaik disimpan ke: best_fold_class_metrics.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f8cb488-aa51-496a-ba8a-d230cd68976f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Total Dataset: 150992\n",
      "📂 Classes: ['A', 'AFIB', 'AFL', 'L', 'N', 'R', 'V']\n",
      "\n",
      "📚 Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_619/2431816455.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "/tmp/ipykernel_619/2431816455.py:70: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "Epoch 1/10:   0%|          | 0/3775 [00:00<?, ?it/s]/tmp/ipykernel_619/2431816455.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_619/2431816455.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "/tmp/ipykernel_619/2431816455.py:70: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "Epoch 1/10:   0%|          | 0/3775 [00:00<?, ?it/s]/tmp/ipykernel_619/2431816455.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 5/10:  25%|██▌       | 949/3775 [02:04<06:12,  7.58it/s, loss=0.000636] IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_619/2431816455.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "/tmp/ipykernel_619/2431816455.py:70: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "Epoch 1/10:   0%|          | 0/3775 [00:00<?, ?it/s]/tmp/ipykernel_619/2431816455.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_619/2431816455.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "/tmp/ipykernel_619/2431816455.py:70: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "Epoch 1/10:   0%|          | 0/3775 [00:00<?, ?it/s]/tmp/ipykernel_619/2431816455.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_619/2431816455.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "/tmp/ipykernel_619/2431816455.py:70: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "Epoch 1/10:   0%|          | 0/3775 [00:00<?, ?it/s]/tmp/ipykernel_619/2431816455.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ringkasan per fold disimpan ke: summary_per_fold.csv\n",
      "✅ Tabel evaluasi lengkap disimpan ke: summary_fold_all_metrics.csv\n",
      "\n",
      "🏆 Fold terbaik: Fold 2 dengan akurasi 0.9932\n",
      "✅ Metrik per kelas dari fold terbaik disimpan ke: best_fold_class_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# ====== Step 1: Dataset dan Transform ======\n",
    "train_dir = \"/workspace/dataset_vit_aug1/dataset_vit_aug/train\"\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "labels = train_dataset.targets  # Label untuk StratifiedKFold\n",
    "\n",
    "print(f\"📊 Total Dataset: {len(train_dataset)}\")\n",
    "print(f\"📂 Classes: {train_dataset.classes}\")\n",
    "\n",
    "# ====== Step 2: Konfigurasi K-Fold dan Training ======\n",
    "n_splits = 5\n",
    "batch_size = 32\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path = \"model_vit_tuning.pth\"\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "all_reports = []\n",
    "fold_accuracies = []\n",
    "\n",
    "# ====== Step 3: Fungsi Hitung Sensitivity dan Specificity ======\n",
    "def calculate_specificity_sensitivity(y_true, y_pred, labels):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=range(len(labels)))\n",
    "    metrics = {}\n",
    "    for i, label in enumerate(labels):\n",
    "        TP = cm[i, i]\n",
    "        FN = cm[i, :].sum() - TP\n",
    "        FP = cm[:, i].sum() - TP\n",
    "        TN = cm.sum() - (TP + FP + FN)\n",
    "        sensitivity = TP / (TP + FN) if TP + FN != 0 else 0\n",
    "        specificity = TN / (TN + FP) if TN + FP != 0 else 0\n",
    "        metrics[label] = {'sensitivity': sensitivity, 'specificity': specificity}\n",
    "    return metrics\n",
    "\n",
    "# ====== Step 4: Proses K-Fold Cross Validation ======\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(labels)), labels)):\n",
    "    print(f\"\\n📚 Fold {fold + 1}\")\n",
    "\n",
    "    train_subset = Subset(train_dataset, train_idx)\n",
    "    val_subset = Subset(train_dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Load dan sesuaikan model\n",
    "    model = models.vit_b_16(pretrained=True)\n",
    "    model.heads = nn.Sequential(\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(model.heads.head.in_features, len(train_dataset.classes))\n",
    "    )\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # ====== Step 5: Proses Training per Fold ======\n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/10\", leave=False)\n",
    "        for images, labels in loop:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # ====== Step 6: Evaluasi Model ======\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            y_pred.extend(preds)\n",
    "            y_true.extend(labels.numpy())\n",
    "\n",
    "    report = classification_report(y_true, y_pred, output_dict=True, target_names=train_dataset.classes)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    sensi_speci = calculate_specificity_sensitivity(y_true, y_pred, train_dataset.classes)\n",
    "\n",
    "    fold_result = {\n",
    "        'fold': fold + 1,\n",
    "        'accuracy': accuracy,\n",
    "        'report': report,\n",
    "        'sensi_speci': sensi_speci\n",
    "    }\n",
    "    all_reports.append(fold_result)\n",
    "    fold_accuracies.append({'Fold': f'Fold {fold+1}', 'Accuracy': accuracy})\n",
    "\n",
    "# ====== Step 7: Simpan Evaluasi Detail Per Fold ======\n",
    "rows = []\n",
    "for fold_result in all_reports:\n",
    "    fold_number = fold_result['fold']\n",
    "    accuracy = fold_result['accuracy']\n",
    "    report = fold_result['report']\n",
    "    sensi_speci = fold_result['sensi_speci']\n",
    "\n",
    "    for cls in train_dataset.classes:\n",
    "        precision = report[cls]['precision']\n",
    "        recall = report[cls]['recall']\n",
    "        f1 = report[cls]['f1-score']\n",
    "        support = report[cls]['support']\n",
    "        sensitivity = sensi_speci[cls]['sensitivity']\n",
    "        specificity = sensi_speci[cls]['specificity']\n",
    "\n",
    "        row = {\n",
    "            'Fold': f\"Fold {fold_number}\",\n",
    "            'Class': cls,\n",
    "            'Accuracy': round(accuracy, 4),\n",
    "            'Precision': round(precision, 4),\n",
    "            'Recall': round(recall, 4),\n",
    "            'F1-Score': round(f1, 4),\n",
    "            'Support': support,\n",
    "            'Sensitivity': round(sensitivity, 4),\n",
    "            'Specificity': round(specificity, 4)\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "df_summary = pd.DataFrame(rows)\n",
    "df_summary.to_csv(\"kfold_finetune_vit_evaluation1.csv\", index=False)\n",
    "\n",
    "# ====== Step 7B: Simpan Ringkasan Evaluasi Per Fold (tanpa per kelas) ======\n",
    "summary_per_fold = []\n",
    "\n",
    "for fold_result in all_reports:\n",
    "    fold_number = fold_result['fold']\n",
    "    accuracy = fold_result['accuracy']\n",
    "    macro = fold_result['report']['macro avg']\n",
    "\n",
    "    row = {\n",
    "        'Fold': f'Fold {fold_number}',\n",
    "        'Accuracy': round(accuracy, 4),\n",
    "        'Macro Precision': round(macro['precision'], 4),\n",
    "        'Macro Recall': round(macro['recall'], 4),\n",
    "        'Macro F1-Score': round(macro['f1-score'], 4)\n",
    "    }\n",
    "    summary_per_fold.append(row)\n",
    "\n",
    "df_fold_summary = pd.DataFrame(summary_per_fold)\n",
    "df_fold_summary.to_csv(\"summary_per_fold.csv\", index=False)\n",
    "print(\"✅ Ringkasan per fold disimpan ke: summary_per_fold.csv\")\n",
    "# ====== Step 7C: Ringkasan Lengkap Evaluasi per Fold (Full Metrics) ======\n",
    "summary_table = []\n",
    "\n",
    "for fold_result in all_reports:\n",
    "    fold_number = fold_result['fold']\n",
    "    accuracy = fold_result['accuracy']\n",
    "    report = fold_result['report']\n",
    "    sensi_speci = fold_result['sensi_speci']\n",
    "\n",
    "    precision_vals = [report[cls]['precision'] for cls in train_dataset.classes]\n",
    "    recall_vals = [report[cls]['recall'] for cls in train_dataset.classes]\n",
    "    f1_vals = [report[cls]['f1-score'] for cls in train_dataset.classes]\n",
    "    sensitivities = [v['sensitivity'] for v in sensi_speci.values()]\n",
    "    specificities = [v['specificity'] for v in sensi_speci.values()]\n",
    "\n",
    "    row = {\n",
    "        'Fold': f'Fold {fold_number}',\n",
    "        'Accuracy': round(accuracy, 6),\n",
    "        'Precision': round(np.mean(precision_vals), 6),\n",
    "        'Sensitivity': round(np.mean(sensitivities), 6),\n",
    "        'Specificity': round(np.mean(specificities), 6),\n",
    "        'F1-Score': round(np.mean(f1_vals), 6)\n",
    "    }\n",
    "    summary_table.append(row)\n",
    "\n",
    "df_full_summary = pd.DataFrame(summary_table)\n",
    "df_full_summary.to_csv(\"summary_fold_all_metrics.csv\", index=False)\n",
    "print(\"✅ Tabel evaluasi lengkap disimpan ke: summary_fold_all_metrics.csv\")\n",
    "\n",
    "# ====== Step 8: Identifikasi Fold Terbaik & Simpan Tabel Detail ======\n",
    "best_fold = max(all_reports, key=lambda x: x['accuracy'])\n",
    "print(f\"\\n🏆 Fold terbaik: Fold {best_fold['fold']} dengan akurasi {best_fold['accuracy']:.4f}\")\n",
    "\n",
    "best_rows = []\n",
    "for cls in train_dataset.classes:\n",
    "    precision = best_fold['report'][cls]['precision']\n",
    "    recall = best_fold['report'][cls]['recall']\n",
    "    f1 = best_fold['report'][cls]['f1-score']\n",
    "    sensitivity = best_fold['sensi_speci'][cls]['sensitivity']\n",
    "    specificity = best_fold['sensi_speci'][cls]['specificity']\n",
    "\n",
    "    best_rows.append({\n",
    "        'Class': cls,\n",
    "        'Precision': round(precision, 4),\n",
    "        'Sensitivity': round(sensitivity, 4),\n",
    "        'Specificity': round(specificity, 4),\n",
    "        'F1-Score': round(f1, 4)\n",
    "    })\n",
    "\n",
    "df_best = pd.DataFrame(best_rows)\n",
    "df_best.to_csv(\"best_fold_class_metrics_ViT.csv\", index=False)\n",
    "print(\"✅ Metrik per kelas dari fold terbaik disimpan ke: best_fold_class_metrics.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e735cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📟 Device: cuda\n",
      "🧪 Total Data: 33335 samples\n",
      "📂 Classes: ['A', 'AFIB', 'AFL', 'L', 'N', 'R', 'V']\n",
      "\n",
      "📚 Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pravi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pravi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Evaluating Fold 1: 100%|██████████| 209/209 [01:53<00:00,  1.83it/s]\n",
      "c:\\Users\\pravi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pravi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Fold 2: 100%|██████████| 209/209 [01:58<00:00,  1.77it/s]\n",
      "c:\\Users\\pravi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pravi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Fold 3: 100%|██████████| 209/209 [02:01<00:00,  1.72it/s]\n",
      "c:\\Users\\pravi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pravi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Fold 4: 100%|██████████| 209/209 [01:59<00:00,  1.74it/s]\n",
      "c:\\Users\\pravi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pravi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Fold 5: 100%|██████████| 209/209 [01:59<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏆 Fold terbaik: Fold 1 dengan akurasi 0.9924\n",
      "🖼️ Confusion matrix disimpan ke: results_eval_kfold_vit/confusion_matrix_fold_1.png\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ====== Device Setup ======\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"📟 Device: {device}\")\n",
    "\n",
    "# ====== Load Dataset dari test_dir ======\n",
    "test_dir = \"dataset_vit/test\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "labels = dataset.targets\n",
    "classes = dataset.classes\n",
    "print(f\"🧪 Total Data: {len(dataset)} samples\")\n",
    "print(f\"📂 Classes: {classes}\")\n",
    "\n",
    "# ====== K-Fold Config ======\n",
    "n_splits = 5\n",
    "batch_size = 32\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# ====== Fungsi Hitung Sensitivity & Specificity ======\n",
    "def calculate_specificity_sensitivity(y_true, y_pred, labels):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=range(len(labels)))\n",
    "    metrics = {}\n",
    "    for i, label in enumerate(labels):\n",
    "        TP = cm[i, i]\n",
    "        FN = cm[i, :].sum() - TP\n",
    "        FP = cm[:, i].sum() - TP\n",
    "        TN = cm.sum() - (TP + FP + FN)\n",
    "        sensitivity = TP / (TP + FN) if TP + FN != 0 else 0\n",
    "        specificity = TN / (TN + FP) if TN + FP != 0 else 0\n",
    "        metrics[label] = {'sensitivity': sensitivity, 'specificity': specificity}\n",
    "    return metrics\n",
    "\n",
    "# ====== Step 1: Evaluasi K-Fold ======\n",
    "all_reports = []\n",
    "\n",
    "for fold, (_, val_idx) in enumerate(skf.split(np.zeros(len(labels)), labels)):\n",
    "    print(f\"\\n📚 Fold {fold + 1}\")\n",
    "    val_subset = Subset(dataset, val_idx)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Load Model\n",
    "    model = models.vit_b_16(pretrained=True)\n",
    "    model.heads = nn.Sequential(\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(model.heads.head.in_features, len(classes))\n",
    "    )\n",
    "    model.load_state_dict(torch.load(\"model_vit_tuning.pth\", map_location=device))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels_batch in tqdm(val_loader, desc=f\"Evaluating Fold {fold+1}\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            y_pred.extend(preds)\n",
    "            y_true.extend(labels_batch.numpy())\n",
    "\n",
    "    report = classification_report(y_true, y_pred, output_dict=True, target_names=classes)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    sensi_speci = calculate_specificity_sensitivity(y_true, y_pred, classes)\n",
    "\n",
    "    all_reports.append({\n",
    "        'fold': fold + 1,\n",
    "        'accuracy': accuracy,\n",
    "        'report': report,\n",
    "        'sensi_speci': sensi_speci,\n",
    "        'y_true': y_true,\n",
    "        'y_pred': y_pred\n",
    "    })\n",
    "\n",
    "# ====== Step 2: Simpan Detail Evaluasi Tiap Fold ======\n",
    "rows = []\n",
    "for fold_result in all_reports:\n",
    "    fold = fold_result['fold']\n",
    "    report = fold_result['report']\n",
    "    sensi_speci = fold_result['sensi_speci']\n",
    "    acc = fold_result['accuracy']\n",
    "    for cls in classes:\n",
    "        rows.append({\n",
    "            'Fold': f\"Fold {fold}\",\n",
    "            'Class': cls,\n",
    "            'Accuracy': round(acc, 4),\n",
    "            'Precision': round(report[cls]['precision'], 4),\n",
    "            'Recall': round(report[cls]['recall'], 4),\n",
    "            'F1-Score': round(report[cls]['f1-score'], 4),\n",
    "            'Sensitivity': round(sensi_speci[cls]['sensitivity'], 4),\n",
    "            'Specificity': round(sensi_speci[cls]['specificity'], 4),\n",
    "            'Support': report[cls]['support']\n",
    "        })\n",
    "df_detail = pd.DataFrame(rows)\n",
    "os.makedirs(\"results_eval_kfold_vit\", exist_ok=True)\n",
    "df_detail.to_csv(\"results_eval_kfold_vit/kfold_detail_vit_tuned.csv\", index=False)\n",
    "\n",
    "# ====== Step 3: Simpan Ringkasan per Fold ======\n",
    "summary_per_fold = []\n",
    "for result in all_reports:\n",
    "    macro = result['report']['macro avg']\n",
    "    summary_per_fold.append({\n",
    "        'Fold': f\"Fold {result['fold']}\",\n",
    "        'Accuracy': round(result['accuracy'], 4),\n",
    "        'Macro Precision': round(macro['precision'], 4),\n",
    "        'Macro Recall': round(macro['recall'], 4),\n",
    "        'Macro F1-Score': round(macro['f1-score'], 4)\n",
    "    })\n",
    "df_summary = pd.DataFrame(summary_per_fold)\n",
    "df_summary.to_csv(\"results_eval_kfold_vit/kfold_summary_vit_tuned.csv\", index=False)\n",
    "\n",
    "# ====== Step 4: Ringkasan Lengkap Rata-rata Metrik ======\n",
    "summary_table = []\n",
    "for result in all_reports:\n",
    "    fold = result['fold']\n",
    "    rep = result['report']\n",
    "    sensi_speci = result['sensi_speci']\n",
    "    precision_vals = [rep[cls]['precision'] for cls in classes]\n",
    "    recall_vals = [rep[cls]['recall'] for cls in classes]\n",
    "    f1_vals = [rep[cls]['f1-score'] for cls in classes]\n",
    "    sensitivities = [v['sensitivity'] for v in sensi_speci.values()]\n",
    "    specificities = [v['specificity'] for v in sensi_speci.values()]\n",
    "    summary_table.append({\n",
    "        'Fold': f\"Fold {fold}\",\n",
    "        'Accuracy': round(result['accuracy'], 6),\n",
    "        'Precision': round(np.mean(precision_vals), 6),\n",
    "        'Sensitivity': round(np.mean(sensitivities), 6),\n",
    "        'Specificity': round(np.mean(specificities), 6),\n",
    "        'F1-Score': round(np.mean(f1_vals), 6)\n",
    "    })\n",
    "df_all_summary = pd.DataFrame(summary_table)\n",
    "df_all_summary.to_csv(\"results_eval_kfold_vit/kfold_full_summary_vit_tuned.csv\", index=False)\n",
    "\n",
    "# ====== Step 5: Fold Terbaik + Confusion Matrix ======\n",
    "best_fold = max(all_reports, key=lambda x: x['accuracy'])\n",
    "print(f\"\\n🏆 Fold terbaik: Fold {best_fold['fold']} dengan akurasi {best_fold['accuracy']:.4f}\")\n",
    "\n",
    "# Simpan Metrik Per Kelas dari Fold Terbaik\n",
    "best_rows = []\n",
    "for cls in classes:\n",
    "    best_rows.append({\n",
    "        'Class': cls,\n",
    "        'Precision': round(best_fold['report'][cls]['precision'], 4),\n",
    "        'Sensitivity': round(best_fold['sensi_speci'][cls]['sensitivity'], 4),\n",
    "        'Specificity': round(best_fold['sensi_speci'][cls]['specificity'], 4),\n",
    "        'F1-Score': round(best_fold['report'][cls]['f1-score'], 4)\n",
    "    })\n",
    "df_best = pd.DataFrame(best_rows)\n",
    "df_best.to_csv(\"results_eval_kfold_vit/best_fold_class_metrics_vit.csv\", index=False)\n",
    "\n",
    "# Plot Confusion Matrix Fold Terbaik\n",
    "cm = confusion_matrix(best_fold['y_true'], best_fold['y_pred'])\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(f\"Confusion Matrix - Fold {best_fold['fold']}\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"results_eval_kfold_vit/confusion_matrix_fold_{best_fold['fold']}.png\")\n",
    "plt.close()\n",
    "print(f\"🖼️ Confusion matrix disimpan ke: results_eval_kfold_vit/confusion_matrix_fold_{best_fold['fold']}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72f22f9c-b763-4da1-ab81-73febb830e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📟 Device: cuda\n",
      "📊 Total Train Data: 150992 samples\n",
      "📂 Classes: ['A', 'AFIB', 'AFL', 'L', 'N', 'R', 'V']\n",
      "\n",
      "📚 Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pravi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pravi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Evaluating Fold 1: 100%|██████████| 944/944 [09:09<00:00,  1.72it/s]\n",
      "c:\\Users\\pravi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pravi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Fold 2: 100%|██████████| 944/944 [09:04<00:00,  1.73it/s]\n",
      "c:\\Users\\pravi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pravi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Fold 3: 100%|██████████| 944/944 [08:47<00:00,  1.79it/s]\n",
      "c:\\Users\\pravi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pravi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Fold 4: 100%|██████████| 944/944 [08:30<00:00,  1.85it/s]\n",
      "c:\\Users\\pravi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pravi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Fold 5: 100%|██████████| 944/944 [08:28<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏆 Fold terbaik: Fold 4 dengan akurasi 0.9903\n",
      "🖼️ Confusion matrix disimpan ke: results_eval_kfold_vit_train/confusion_matrix_fold_4_train.png\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ====== Device Setup ======\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"📟 Device: {device}\")\n",
    "\n",
    "# ====== Load Dataset dari train_dir ======\n",
    "train_dir = \"dataset_vit_aug/train\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "labels = dataset.targets\n",
    "classes = dataset.classes\n",
    "print(f\"📊 Total Train Data: {len(dataset)} samples\")\n",
    "print(f\"📂 Classes: {classes}\")\n",
    "\n",
    "# ====== K-Fold Config ======\n",
    "n_splits = 5\n",
    "batch_size = 32\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# ====== Fungsi Hitung Sensitivity & Specificity ======\n",
    "def calculate_specificity_sensitivity(y_true, y_pred, labels):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=range(len(labels)))\n",
    "    metrics = {}\n",
    "    for i, label in enumerate(labels):\n",
    "        TP = cm[i, i]\n",
    "        FN = cm[i, :].sum() - TP\n",
    "        FP = cm[:, i].sum() - TP\n",
    "        TN = cm.sum() - (TP + FP + FN)\n",
    "        sensitivity = TP / (TP + FN) if TP + FN != 0 else 0\n",
    "        specificity = TN / (TN + FP) if TN + FP != 0 else 0\n",
    "        metrics[label] = {'sensitivity': sensitivity, 'specificity': specificity}\n",
    "    return metrics\n",
    "\n",
    "# ====== Step 1: Evaluasi K-Fold ======\n",
    "all_reports = []\n",
    "\n",
    "for fold, (_, val_idx) in enumerate(skf.split(np.zeros(len(labels)), labels)):\n",
    "    print(f\"\\n📚 Fold {fold + 1}\")\n",
    "    val_subset = Subset(dataset, val_idx)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Load Model\n",
    "    model = models.vit_b_16(pretrained=True)\n",
    "    model.heads = nn.Sequential(\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(model.heads.head.in_features, len(classes))\n",
    "    )\n",
    "    model.load_state_dict(torch.load(\"model_vit_tuning.pth\", map_location=device))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels_batch in tqdm(val_loader, desc=f\"Evaluating Fold {fold+1}\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            y_pred.extend(preds)\n",
    "            y_true.extend(labels_batch.numpy())\n",
    "\n",
    "    report = classification_report(y_true, y_pred, output_dict=True, target_names=classes)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    sensi_speci = calculate_specificity_sensitivity(y_true, y_pred, classes)\n",
    "\n",
    "    all_reports.append({\n",
    "        'fold': fold + 1,\n",
    "        'accuracy': accuracy,\n",
    "        'report': report,\n",
    "        'sensi_speci': sensi_speci,\n",
    "        'y_true': y_true,\n",
    "        'y_pred': y_pred\n",
    "    })\n",
    "\n",
    "# ====== Step 2: Simpan Detail Evaluasi Tiap Fold ======\n",
    "rows = []\n",
    "for fold_result in all_reports:\n",
    "    fold = fold_result['fold']\n",
    "    report = fold_result['report']\n",
    "    sensi_speci = fold_result['sensi_speci']\n",
    "    acc = fold_result['accuracy']\n",
    "    for cls in classes:\n",
    "        rows.append({\n",
    "            'Fold': f\"Fold {fold}\",\n",
    "            'Class': cls,\n",
    "            'Accuracy': round(acc, 4),\n",
    "            'Precision': round(report[cls]['precision'], 4),\n",
    "            'Recall': round(report[cls]['recall'], 4),\n",
    "            'F1-Score': round(report[cls]['f1-score'], 4),\n",
    "            'Sensitivity': round(sensi_speci[cls]['sensitivity'], 4),\n",
    "            'Specificity': round(sensi_speci[cls]['specificity'], 4),\n",
    "            'Support': report[cls]['support']\n",
    "        })\n",
    "df_detail = pd.DataFrame(rows)\n",
    "os.makedirs(\"results_eval_kfold_vit_train\", exist_ok=True)\n",
    "df_detail.to_csv(\"results_eval_kfold_vit_train/kfold_detail_vit_tuned_train.csv\", index=False)\n",
    "\n",
    "# ====== Step 3: Simpan Ringkasan per Fold ======\n",
    "summary_per_fold = []\n",
    "for result in all_reports:\n",
    "    macro = result['report']['macro avg']\n",
    "    summary_per_fold.append({\n",
    "        'Fold': f\"Fold {result['fold']}\",\n",
    "        'Accuracy': round(result['accuracy'], 4),\n",
    "        'Macro Precision': round(macro['precision'], 4),\n",
    "        'Macro Recall': round(macro['recall'], 4),\n",
    "        'Macro F1-Score': round(macro['f1-score'], 4)\n",
    "    })\n",
    "df_summary = pd.DataFrame(summary_per_fold)\n",
    "df_summary.to_csv(\"results_eval_kfold_vit_train/kfold_summary_vit_tuned_train.csv\", index=False)\n",
    "\n",
    "# ====== Step 4: Ringkasan Lengkap Rata-rata Metrik ======\n",
    "summary_table = []\n",
    "for result in all_reports:\n",
    "    fold = result['fold']\n",
    "    rep = result['report']\n",
    "    sensi_speci = result['sensi_speci']\n",
    "    precision_vals = [rep[cls]['precision'] for cls in classes]\n",
    "    recall_vals = [rep[cls]['recall'] for cls in classes]\n",
    "    f1_vals = [rep[cls]['f1-score'] for cls in classes]\n",
    "    sensitivities = [v['sensitivity'] for v in sensi_speci.values()]\n",
    "    specificities = [v['specificity'] for v in sensi_speci.values()]\n",
    "    summary_table.append({\n",
    "        'Fold': f\"Fold {fold}\",\n",
    "        'Accuracy': round(result['accuracy'], 6),\n",
    "        'Precision': round(np.mean(precision_vals), 6),\n",
    "        'Sensitivity': round(np.mean(sensitivities), 6),\n",
    "        'Specificity': round(np.mean(specificities), 6),\n",
    "        'F1-Score': round(np.mean(f1_vals), 6)\n",
    "    })\n",
    "df_all_summary = pd.DataFrame(summary_table)\n",
    "df_all_summary.to_csv(\"results_eval_kfold_vit_train/kfold_full_summary_vit_tuned_train.csv\", index=False)\n",
    "\n",
    "# ====== Step 5: Fold Terbaik + Confusion Matrix ======\n",
    "best_fold = max(all_reports, key=lambda x: x['accuracy'])\n",
    "print(f\"\\n🏆 Fold terbaik: Fold {best_fold['fold']} dengan akurasi {best_fold['accuracy']:.4f}\")\n",
    "\n",
    "# Simpan Metrik Per Kelas dari Fold Terbaik\n",
    "best_rows = []\n",
    "for cls in classes:\n",
    "    best_rows.append({\n",
    "        'Class': cls,\n",
    "        'Precision': round(best_fold['report'][cls]['precision'], 4),\n",
    "        'Sensitivity': round(best_fold['sensi_speci'][cls]['sensitivity'], 4),\n",
    "        'Specificity': round(best_fold['sensi_speci'][cls]['specificity'], 4),\n",
    "        'F1-Score': round(best_fold['report'][cls]['f1-score'], 4)\n",
    "    })\n",
    "df_best = pd.DataFrame(best_rows)\n",
    "df_best.to_csv(\"results_eval_kfold_vit_train/best_fold_class_metrics_vit_train.csv\", index=False)\n",
    "\n",
    "# Plot Confusion Matrix Fold Terbaik\n",
    "cm = confusion_matrix(best_fold['y_true'], best_fold['y_pred'])\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(f\"Confusion Matrix - Fold {best_fold['fold']} (Train Data)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"results_eval_kfold_vit_train/confusion_matrix_fold_{best_fold['fold']}_train.png\")\n",
    "plt.close()\n",
    "print(f\"🖼️ Confusion matrix disimpan ke: results_eval_kfold_vit_train/confusion_matrix_fold_{best_fold['fold']}_train.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
